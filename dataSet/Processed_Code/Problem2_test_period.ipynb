{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d9d8b2-9495-496d-b97c-8b8548e6b98f",
   "metadata": {},
   "source": [
    "# 1.Statistics for DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e91d460-da0b-4e88-8e40-412708283ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week-by-Week Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>Number of seg.nii.gz Files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WK12</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WK14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WK20</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WK21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WK30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WK32</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WK33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WK36</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WK37</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Total</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Week  Number of seg.nii.gz Files\n",
       "0   WK12                          35\n",
       "1   WK14                           1\n",
       "2   WK20                          38\n",
       "3   WK21                           2\n",
       "4   WK30                           1\n",
       "5   WK32                          33\n",
       "6   WK33                           1\n",
       "7   WK36                          19\n",
       "8   WK37                           2\n",
       "9  Total                         132"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pregnancy Stage Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancy Stage</th>\n",
       "      <th>Number of seg.nii.gz Files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Early Pregnancy (Week: 0-19)</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mid Pregnancy (Week: 20-30)</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Late Pregnancy (Week 31-40)</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Total</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Pregnancy Stage  Number of seg.nii.gz Files\n",
       "0  Early Pregnancy (Week: 0-19)                          36\n",
       "1   Mid Pregnancy (Week: 20-30)                          41\n",
       "2   Late Pregnancy (Week 31-40)                          55\n",
       "3                         Total                         132"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Specify the target folder path\n",
    "folder_path = \"../Processed/PII_GZ\"\n",
    "\n",
    "# Define dictionaries to store the statistics\n",
    "week_count = defaultdict(int)  # Count of seg.nii.gz files per week\n",
    "total_seg_count = 0  # Total count of seg.nii.gz files\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\"seg.nii.gz\"):\n",
    "        # Extract the week information from WKXX\n",
    "        match = re.search(r'WK(\\d{2,3})_seg\\.nii\\.gz', file_name)\n",
    "        if match:\n",
    "            week = int(match.group(1))  # Convert week to integer\n",
    "            week_count[week] += 1\n",
    "            total_seg_count += 1\n",
    "\n",
    "# Define pregnancy stages\n",
    "pregnancy_stages = {\n",
    "    \"Early Pregnancy (Week: 0-19)\": range(0, 20),  # 0-19 weeks\n",
    "    \"Mid Pregnancy (Week: 20-30)\": range(20, 31),  # 20-30 weeks\n",
    "    \"Late Pregnancy (Week 31-40)\": range(31, 41),  # 31-40 weeks\n",
    "}\n",
    "\n",
    "# Initialize counts for each pregnancy stage\n",
    "stage_counts = {stage: 0 for stage in pregnancy_stages}\n",
    "\n",
    "# Aggregate counts into stages\n",
    "for week, count in week_count.items():\n",
    "    for stage, weeks in pregnancy_stages.items():\n",
    "        if week in weeks:\n",
    "            stage_counts[stage] += count\n",
    "            break\n",
    "\n",
    "# Create the week-by-week DataFrame\n",
    "week_data = {\"Week\": [], \"Number of seg.nii.gz Files\": []}\n",
    "for week, count in sorted(week_count.items()):\n",
    "    week_data[\"Week\"].append(f\"WK{week}\")\n",
    "    week_data[\"Number of seg.nii.gz Files\"].append(count)\n",
    "\n",
    "# Add the total count\n",
    "week_data[\"Week\"].append(\"Total\")\n",
    "week_data[\"Number of seg.nii.gz Files\"].append(total_seg_count)\n",
    "\n",
    "week_df = pd.DataFrame(week_data)\n",
    "\n",
    "# Create the pregnancy stage DataFrame\n",
    "stage_data = {\"Pregnancy Stage\": [], \"Number of seg.nii.gz Files\": []}\n",
    "for stage, count in stage_counts.items():\n",
    "    stage_data[\"Pregnancy Stage\"].append(stage)\n",
    "    stage_data[\"Number of seg.nii.gz Files\"].append(count)\n",
    "\n",
    "# Add total for pregnancy stage\n",
    "stage_data[\"Pregnancy Stage\"].append(\"Total\")\n",
    "stage_data[\"Number of seg.nii.gz Files\"].append(sum(stage_counts.values()))\n",
    "\n",
    "stage_df = pd.DataFrame(stage_data)\n",
    "\n",
    "# Display the two tables separately\n",
    "print(\"Week-by-Week Statistics:\")\n",
    "display(week_df)\n",
    "\n",
    "print(\"\\nPregnancy Stage Statistics:\")\n",
    "display(stage_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c29d8f-f48a-479a-8762-f9fe2d41bab1",
   "metadata": {},
   "source": [
    "# 2. Automatic file format conversion: nii to nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48a73c54-a8fc-45ec-a430-b5180682ff2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion to .nii.gz completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import SimpleITK as sitk\n",
    "\n",
    "# Define input and output folders\n",
    "input_folder = \"../Raw/ForSeg\"\n",
    "output_folder = \"../Processed/PII_GZ\"\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Traverse all subfolders and files in the ForSeg folder\n",
    "for folder_name in os.listdir(input_folder):\n",
    "    folder_path = os.path.join(input_folder, folder_name)\n",
    "    \n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    \n",
    "    # Process b0_img.nii and seg.nii\n",
    "    b0_img_file = os.path.join(folder_path, \"b0_img.nii\")\n",
    "    seg_file = os.path.join(folder_path, \"seg.nii\")\n",
    "    \n",
    "    if os.path.exists(b0_img_file):\n",
    "        # Read and compress to nii.gz\n",
    "        img = sitk.ReadImage(b0_img_file)\n",
    "        compressed_file_path = os.path.join(output_folder, folder_name + \"_b0_img.nii.gz\")\n",
    "        sitk.WriteImage(img, compressed_file_path)\n",
    "    \n",
    "    if os.path.exists(seg_file):\n",
    "        # Read and compress to nii.gz\n",
    "        img = sitk.ReadImage(seg_file)\n",
    "        compressed_file_path = os.path.join(output_folder, folder_name + \"_seg.nii.gz\")\n",
    "        sitk.WriteImage(img, compressed_file_path)\n",
    "\n",
    "print(\"Conversion to .nii.gz completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c2ad31-a774-49bd-9b1d-0c21fa4ce5bb",
   "metadata": {},
   "source": [
    "# 3. Extract each folder's original MRI and its segmentation result MRI into images, labels, and folders respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b328edb8-2eac-4db5-a22e-d71330cd384a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task completed! File copies and CSV log created. \n",
      " Extract each folder's original MRI and its segmentation result MRI into images, labels, and folders respectively.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "\n",
    "# Define the file path\n",
    "forseg_path = \"../Processed/PII_GZ\"  # Now use the compressed file path\n",
    "images_path = os.path.join(\"../Processed/PII_Full\", \"images\")\n",
    "labels_path = os.path.join(\"../Processed/PII_Full\", \"labels\")\n",
    "csv_file = os.path.join(\"../Processed/PII_Full\", \"PII_log.csv\")\n",
    "\n",
    "if not os.path.exists(forseg_path):\n",
    "    raise FileNotFoundError(f\"Path doesnt exit: {forseg_path}\")\n",
    "\n",
    "# If the images and labels folders do not exist, create them\n",
    "os.makedirs(images_path, exist_ok=True)\n",
    "os.makedirs(labels_path, exist_ok=True)\n",
    "\n",
    "# Initialize the global file number count\n",
    "global_count = 1\n",
    "\n",
    "# Open the CSV file and prepare to record the mapping between raw and separation\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Original MRI File\", \"Original Seg File\", \"Dataset\", \"New Filename\"])\n",
    "    \n",
    "    # Traverse all files under PII_GZ\n",
    "    for filename in os.listdir(forseg_path):\n",
    "        if filename.endswith(\"_b0_img.nii.gz\"):\n",
    "            b0_img_file = os.path.join(forseg_path, filename)\n",
    "            seg_file = os.path.join(forseg_path, filename.replace(\"_b0_img.nii.gz\", \"_seg.nii.gz\"))\n",
    "            \n",
    "            if os.path.exists(b0_img_file) and os.path.exists(seg_file):\n",
    "                new_file_name = f\"PII_{str(global_count).zfill(3)}.nii.gz\"\n",
    "                \n",
    "                # Copy b0_img.nii.gz to the images folder\n",
    "                new_b0_img_path = os.path.join(images_path, new_file_name)\n",
    "                shutil.copy2(b0_img_file, new_b0_img_path)\n",
    "                \n",
    "                # Copy seg.nii.gz to the labels folder\n",
    "                new_seg_path = os.path.join(labels_path, new_file_name)\n",
    "                shutil.copy2(seg_file, new_seg_path)\n",
    "                \n",
    "                # Logging to CSV file\n",
    "                writer.writerow([b0_img_file, seg_file, \"images\", new_file_name])\n",
    "                writer.writerow([b0_img_file, seg_file, \"labels\", new_file_name])\n",
    "                \n",
    "                # Increment global count\n",
    "                global_count += 1\n",
    "\n",
    "print(\"Task completed! File copies and CSV log created. \\n Extract each folder's original MRI and its segmentation result MRI into images, labels, and folders respectively.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdb1dd5-6ea7-40f7-9d2c-fc1f4fb7a1ff",
   "metadata": {},
   "source": [
    "# 4.Dataset division by week range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d9b5912-9dca-4074-a24a-21d4014989d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully split into training and testing sets based on the week range (31, 40)!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "\n",
    "# Step 3: Split data into train/test sets based on week range using PII_log.csv\n",
    "def split_data_by_week_range(log_file, input_folder, output_base_folder, week_range):\n",
    "    \"\"\"\n",
    "    Split the dataset into training and testing sets based on the week range specified in PII_log.csv.\n",
    "    \"\"\"\n",
    "    # Read the PII_log.csv file\n",
    "    df = pd.read_csv(log_file, header=0)\n",
    "    \n",
    "    # Define paths to the images and labels folders\n",
    "    images_path = os.path.join(input_folder, \"images\")\n",
    "    labels_path = os.path.join(input_folder, \"labels\")\n",
    "    \n",
    "    # Create a range name for the output folder\n",
    "    range_name = f\"{week_range[0]}-{week_range[1]}\"\n",
    "    output_folder = os.path.join(output_base_folder, f\"PII_{range_name}\")\n",
    "    \n",
    "    # Define paths for train/test subfolders\n",
    "    images_tr_path = os.path.join(output_folder, \"imagesTr\")\n",
    "    labels_tr_path = os.path.join(output_folder, \"labelsTr\")\n",
    "    images_ts_path = os.path.join(output_folder, \"imagesTs\")\n",
    "    labels_ts_path = os.path.join(output_folder, \"labelsTs\")\n",
    "    \n",
    "    # Create the output directories\n",
    "    os.makedirs(images_tr_path, exist_ok=True)\n",
    "    os.makedirs(labels_tr_path, exist_ok=True)\n",
    "    os.makedirs(images_ts_path, exist_ok=True)\n",
    "    os.makedirs(labels_ts_path, exist_ok=True)\n",
    "\n",
    "    # Paths for train and test log files\n",
    "    train_log = os.path.join(output_folder, \"train_log.csv\")\n",
    "    test_log = os.path.join(output_folder, \"test_log.csv\")\n",
    "\n",
    "    # Open the log files for writing\n",
    "    with open(train_log, mode='w', newline='') as train_file, \\\n",
    "         open(test_log, mode='w', newline='') as test_file:\n",
    "        train_writer = csv.writer(train_file)\n",
    "        test_writer = csv.writer(test_file)\n",
    "        \n",
    "        # Write the headers for both CSV files\n",
    "        train_writer.writerow([\"Original MRI Path\", \"Original Seg Path\", \"New MRI Path\", \"New Seg Path\"])\n",
    "        test_writer.writerow([\"Original MRI Path\", \"Original Seg Path\", \"New MRI Path\", \"New Seg Path\"])\n",
    "\n",
    "        # Iterate over rows in the PII_log.csv file\n",
    "        for _, row in df.iterrows():\n",
    "            # Define the paths for the original images and labels\n",
    "            original_img = os.path.join(images_path, row[\"New Filename\"])\n",
    "            original_seg = os.path.join(labels_path, row[\"New Filename\"])\n",
    "            \n",
    "            # Extract the week number from the original MRI file path\n",
    "            week_num = int(row[\"Original MRI File\"].split(\"WK\")[1].split(\"_\")[0])\n",
    "\n",
    "            if week_range[0] <= week_num <= week_range[1]:\n",
    "                # If the week number is within the specified range, add to the test set\n",
    "                test_img = os.path.join(images_ts_path, row[\"New Filename\"])\n",
    "                test_seg = os.path.join(labels_ts_path, row[\"New Filename\"])\n",
    "                \n",
    "                # Copy files to the test set\n",
    "                shutil.copy2(original_img, test_img)\n",
    "                shutil.copy2(original_seg, test_seg)\n",
    "                \n",
    "                # Log the operation in the test log\n",
    "                test_writer.writerow([row[\"Original MRI File\"], row[\"Original Seg File\"], test_img, test_seg])\n",
    "            else:\n",
    "                # Otherwise, add to the train set\n",
    "                train_img = os.path.join(images_tr_path, row[\"New Filename\"])\n",
    "                train_seg = os.path.join(labels_tr_path, row[\"New Filename\"])\n",
    "                \n",
    "                # Copy files to the train set\n",
    "                shutil.copy2(original_img, train_img)\n",
    "                shutil.copy2(original_seg, train_seg)\n",
    "                \n",
    "                # Log the operation in the train log\n",
    "                train_writer.writerow([row[\"Original MRI File\"], row[\"Original Seg File\"], train_img, train_seg])\n",
    "\n",
    "    print(f\"Data has been successfully split into training and testing sets based on the week range {week_range}!\")\n",
    "\n",
    "log_file = \"../Processed/PII_Full/PII_log.csv\"\n",
    "input_folder = \"../Processed/PII_Full\"\n",
    "output_folder = \"../Processed\"\n",
    "# week_range = (0, 19)  # Specify the week range for the test set\n",
    "# week_range = (20, 30)  # Specify the week range for the test set\n",
    "# week_range = (31, 40)  # Specify the week range for the test set\n",
    "# week_range = (0, 30)  # Specify the week range for the test set\n",
    "# week_range = (20, 30)  # Specify the week range for the test set\n",
    "# week_range = (31, 40)  # Specify the week range for the test set\n",
    "split_data_by_week_range(log_file, input_folder, output_folder, week_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4797f6-c9bf-451e-94cd-53cf19c34c3a",
   "metadata": {},
   "source": [
    "# 5. Create and modify the relevant json files in the final dataset to form a complete MRI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5993ced9-12c5-4a02-94c0-6f539088dd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json updated successfully at ../Processed/PII_SingleSet_final/31402030\\dataset.json!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Step 4: Update dataset.json\n",
    "def update_dataset_json(output_folder, dataset_name, description, reference, license_info):\n",
    "    \"\"\"\n",
    "    Updates the dataset.json file for the dataset.\n",
    "\n",
    "    Args:\n",
    "        output_folder (str): Path to the folder where the dataset.json will be saved.\n",
    "        dataset_name (str): Name of the dataset.\n",
    "        description (str): Description of the dataset.\n",
    "        reference (str): Reference or citation for the dataset.\n",
    "        license_info (str): License information for the dataset.\n",
    "    \"\"\"\n",
    "    # Define paths for the dataset\n",
    "    json_file_path = os.path.join(output_folder, \"dataset.json\")\n",
    "    images_tr_path = os.path.join(output_folder, \"imagesTr\")\n",
    "    images_ts_path = os.path.join(output_folder, \"imagesTs\")\n",
    "\n",
    "    # Base structure of the dataset.json\n",
    "    data = {\n",
    "        \"name\": dataset_name,\n",
    "        \"description\": description,\n",
    "        \"tensorImageSize\": \"3D\",\n",
    "        \"reference\": reference,\n",
    "        \"licence\": license_info,\n",
    "        \"release\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"modality\": {\n",
    "            \"0\": \"MRI\"\n",
    "        },\n",
    "        \"labels\": {\n",
    "            \"0\": \"background\",\n",
    "            \"1\": \"Placenta in Uterus\"\n",
    "        },\n",
    "        \"training\": [],\n",
    "        \"test\": []\n",
    "    }\n",
    "\n",
    "    # Populate the training section\n",
    "    for img_file in os.listdir(images_tr_path):\n",
    "        if img_file.endswith(\".nii.gz\"):  # Ensure only nii.gz files are considered\n",
    "            data[\"training\"].append({\n",
    "                \"image\": f\"./imagesTr/{img_file}\",\n",
    "                \"label\": f\"./labelsTr/{img_file}\"\n",
    "            })\n",
    "\n",
    "    # Populate the testing section\n",
    "    for img_file in os.listdir(images_ts_path):\n",
    "        if img_file.endswith(\".nii.gz\"):  # Ensure only nii.gz files are considered\n",
    "            data[\"test\"].append(f\"./imagesTs/{img_file}\")\n",
    "\n",
    "    # Update numTraining and numTest based on the counts\n",
    "    data[\"numTraining\"] = len(data[\"training\"])\n",
    "    data[\"numTest\"] = len(data[\"test\"])\n",
    "\n",
    "    # Write the updated data to the dataset.json file\n",
    "    with open(json_file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"dataset.json updated successfully at {json_file_path}!\")\n",
    "\n",
    "# Example usage\n",
    "# output_folder = \"../Processed/PII_00-19\"\n",
    "# output_folder = \"../Processed/PII_20-30\"\n",
    "# output_folder = \"../Processed/PII_31-40\"\n",
    "# output_folder = \"../Processed/PII_SingleSet_final/00192030\"\n",
    "# output_folder = \"../Processed/PII_SingleSet_final/00193140\"\n",
    "# output_folder = \"../Processed/PII_SingleSet_final/20300019\"\n",
    "# output_folder = \"../Processed/PII_SingleSet_final/20303140\"\n",
    "# output_folder = \"../Processed/PII_SingleSet_final/31400019\"\n",
    "output_folder = \"../Processed/PII_SingleSet_final/31402030\"\n",
    "update_dataset_json(\n",
    "    output_folder,\n",
    "    dataset_name=\"Placenta Segmentation\",\n",
    "    description=\"Segmentation of Placenta MRI Data\",\n",
    "    reference=\"Washington University in St. Louis\",\n",
    "    license_info=\"CC BY-NC 4.0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008b44a1-6fbb-4e57-902b-e61df8604824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
